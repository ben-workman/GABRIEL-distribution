{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gabriel.combined_assistant import CombinedAssistant\n",
    "import os\n",
    "\n",
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch request to /Users/elliottmokski/Library/Application Support/GABRIEL Batch Calls/cities_query2.jsonl\n"
     ]
    }
   ],
   "source": [
    "from gabriel.openai_api_calls import *\n",
    "# from prompt_wrapping import *\n",
    "x = call_api('What is the population of London?', 'Be a helpful assistant', 10, 0.9, 'gpt-3.5-turbo',desired_response_format = 'text', seed = None, api_key = 'abc', use_batch = True, custom_id = 'request_3',file_name = 'cities_query2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of 2021, the population of London is estimated to be around 9 million people. However, population estimates can vary depending on the source and the methodology used for calculation.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_api('What is the population of London?', 'Be a helpful assistant', 10, 0.9, 'gpt-3.5-turbo',desired_response_format = 'text', seed = None, api_key = '', use_batch = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/elliottmokski/Library/Application Support/GABRIEL Batch Calls/cities_query2.jsonl'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"custom_id\": \"request_1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"system\", \"content\": \"Be a helpful assistant\"}, {\"role\": \"user\", \"content\": \"What is the population of NYC?\"}], \"temperature\": 0.9, \"max_tokens\": 2000, \"seed\": null, \"response_format\": {\"type\": \"text\"}}}\n",
      "\n",
      "{\"custom_id\": \"request_2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"system\", \"content\": \"Be a helpful assistant\"}, {\"role\": \"user\", \"content\": \"What is the population of Paris?\"}], \"temperature\": 0.9, \"max_tokens\": 2000, \"seed\": null, \"response_format\": {\"type\": \"text\"}}}\n",
      "\n",
      "{\"custom_id\": \"request_3\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"system\", \"content\": \"Be a helpful assistant\"}, {\"role\": \"user\", \"content\": \"What is the population of London?\"}], \"temperature\": 0.9, \"max_tokens\": 2000, \"seed\": null, \"response_format\": {\"type\": \"text\"}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/elliottmokski/Library/Application Support/GABRIEL Batch Calls/cities_query.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = BatchRunner('').run_batch('cities_query','Test for cities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_dict(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: class_to_dict(v) for k, v in obj.items()}\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        return {k: class_to_dict(v) for k, v in obj.__dict__.items()}\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "batch_dict = class_to_dict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>completion_window</th>\n",
       "      <th>created_at</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>input_file_id</th>\n",
       "      <th>object</th>\n",
       "      <th>status</th>\n",
       "      <th>cancelled_at</th>\n",
       "      <th>cancelling_at</th>\n",
       "      <th>completed_at</th>\n",
       "      <th>error_file_id</th>\n",
       "      <th>errors</th>\n",
       "      <th>expired_at</th>\n",
       "      <th>expires_at</th>\n",
       "      <th>failed_at</th>\n",
       "      <th>finalizing_at</th>\n",
       "      <th>in_progress_at</th>\n",
       "      <th>metadata</th>\n",
       "      <th>output_file_id</th>\n",
       "      <th>request_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_wHRk3WUFC5RDOqoTpNPp0Z67</td>\n",
       "      <td>24h</td>\n",
       "      <td>1718810016</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>file-YEgKMlRUpSJLfGNSZV2seofK</td>\n",
       "      <td>batch</td>\n",
       "      <td>validating</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1718896416</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"description\": \"Test for cities\"}</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"completed\": 0, \"failed\": 0, \"total\": 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id completion_window  created_at  \\\n",
       "0  batch_wHRk3WUFC5RDOqoTpNPp0Z67               24h  1718810016   \n",
       "\n",
       "               endpoint                  input_file_id object      status  \\\n",
       "0  /v1/chat/completions  file-YEgKMlRUpSJLfGNSZV2seofK  batch  validating   \n",
       "\n",
       "  cancelled_at cancelling_at completed_at error_file_id errors expired_at  \\\n",
       "0         None          None         None          None   None       None   \n",
       "\n",
       "   expires_at failed_at finalizing_at in_progress_at  \\\n",
       "0  1718896416      None          None           None   \n",
       "\n",
       "                             metadata output_file_id  \\\n",
       "0  {\"description\": \"Test for cities\"}           None   \n",
       "\n",
       "                              request_counts  \n",
       "0  {\"completed\": 0, \"failed\": 0, \"total\": 0}  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def class_to_serializable_dict(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: class_to_serializable_dict(v) for k, v in obj.items()}\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        return {k: class_to_serializable_dict(v) for k, v in obj.__dict__.items()}\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def serialize_nested_dicts(d):\n",
    "    \"\"\"Converts nested dictionaries to JSON strings.\"\"\"\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict) or hasattr(value, '__dict__'):\n",
    "            d[key] = json.dumps(class_to_serializable_dict(value))\n",
    "    return d\n",
    "\n",
    "batch_dict = serialize_nested_dicts(class_to_serializable_dict(t))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame([batch_dict])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>completion_window</th>\n",
       "      <th>created_at</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>input_file_id</th>\n",
       "      <th>object</th>\n",
       "      <th>status</th>\n",
       "      <th>cancelled_at</th>\n",
       "      <th>cancelling_at</th>\n",
       "      <th>completed_at</th>\n",
       "      <th>error_file_id</th>\n",
       "      <th>errors</th>\n",
       "      <th>expired_at</th>\n",
       "      <th>expires_at</th>\n",
       "      <th>failed_at</th>\n",
       "      <th>finalizing_at</th>\n",
       "      <th>in_progress_at</th>\n",
       "      <th>metadata</th>\n",
       "      <th>output_file_id</th>\n",
       "      <th>request_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>batch_wHRk3WUFC5RDOqoTpNPp0Z67</td>\n",
       "      <td>24h</td>\n",
       "      <td>1718810016</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>file-YEgKMlRUpSJLfGNSZV2seofK</td>\n",
       "      <td>batch</td>\n",
       "      <td>validating</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1718896416</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Test for cities</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed</th>\n",
       "      <td>batch_wHRk3WUFC5RDOqoTpNPp0Z67</td>\n",
       "      <td>24h</td>\n",
       "      <td>1718810016</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>file-YEgKMlRUpSJLfGNSZV2seofK</td>\n",
       "      <td>batch</td>\n",
       "      <td>validating</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1718896416</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed</th>\n",
       "      <td>batch_wHRk3WUFC5RDOqoTpNPp0Z67</td>\n",
       "      <td>24h</td>\n",
       "      <td>1718810016</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>file-YEgKMlRUpSJLfGNSZV2seofK</td>\n",
       "      <td>batch</td>\n",
       "      <td>validating</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1718896416</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>batch_wHRk3WUFC5RDOqoTpNPp0Z67</td>\n",
       "      <td>24h</td>\n",
       "      <td>1718810016</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>file-YEgKMlRUpSJLfGNSZV2seofK</td>\n",
       "      <td>batch</td>\n",
       "      <td>validating</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1718896416</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id completion_window  created_at  \\\n",
       "description  batch_wHRk3WUFC5RDOqoTpNPp0Z67               24h  1718810016   \n",
       "completed    batch_wHRk3WUFC5RDOqoTpNPp0Z67               24h  1718810016   \n",
       "failed       batch_wHRk3WUFC5RDOqoTpNPp0Z67               24h  1718810016   \n",
       "total        batch_wHRk3WUFC5RDOqoTpNPp0Z67               24h  1718810016   \n",
       "\n",
       "                         endpoint                  input_file_id object  \\\n",
       "description  /v1/chat/completions  file-YEgKMlRUpSJLfGNSZV2seofK  batch   \n",
       "completed    /v1/chat/completions  file-YEgKMlRUpSJLfGNSZV2seofK  batch   \n",
       "failed       /v1/chat/completions  file-YEgKMlRUpSJLfGNSZV2seofK  batch   \n",
       "total        /v1/chat/completions  file-YEgKMlRUpSJLfGNSZV2seofK  batch   \n",
       "\n",
       "                 status cancelled_at cancelling_at completed_at error_file_id  \\\n",
       "description  validating         None          None         None          None   \n",
       "completed    validating         None          None         None          None   \n",
       "failed       validating         None          None         None          None   \n",
       "total        validating         None          None         None          None   \n",
       "\n",
       "            errors expired_at  expires_at failed_at finalizing_at  \\\n",
       "description   None       None  1718896416      None          None   \n",
       "completed     None       None  1718896416      None          None   \n",
       "failed        None       None  1718896416      None          None   \n",
       "total         None       None  1718896416      None          None   \n",
       "\n",
       "            in_progress_at         metadata output_file_id  request_counts  \n",
       "description           None  Test for cities           None             NaN  \n",
       "completed             None              NaN           None             0.0  \n",
       "failed                None              NaN           None             0.0  \n",
       "total                 None              NaN           None             0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The status of your batch is: completed\n",
      "As of 2021, the population of New York City is estimated to be around 8.4 million people. However, this number can fluctuate with changes in birth rates, migration trends, and other factors.\n",
      "As of 2020, the population of Paris, France is estimated to be around 2.1 million people.\n",
      "The population of London is estimated to be around 9 million people.\n"
     ]
    }
   ],
   "source": [
    "BatchRunner('').collect_batch('batch_4Lx4cDC1wH5HzgdzSavpWolc','cities_query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = '')\n",
    "# client.batches.retrieve(\"batch_lsYz1K5XMMVUgGjsAA7oqvAy\").output_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = client.files.content('file-jIAhkB2uCxMtHgMsngG3i4jP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'batch_req_Y2iA98bZkeDQftJXcceeWLvX',\n",
       " 'custom_id': 'request_1',\n",
       " 'response': {'status_code': 200,\n",
       "  'request_id': '701b09a2ae4de80ca1009066d1fef5e0',\n",
       "  'body': {'id': 'chatcmpl-9bq3AeTUwZAapFcKg7XEuKaVRkvHn',\n",
       "   'object': 'chat.completion',\n",
       "   'created': 1718805244,\n",
       "   'model': 'gpt-3.5-turbo-0125',\n",
       "   'choices': [{'index': 0,\n",
       "     'message': {'role': 'assistant',\n",
       "      'content': 'As of 2021, the population of New York City is estimated to be around 8.4 million people.'},\n",
       "     'logprobs': None,\n",
       "     'finish_reason': 'stop'}],\n",
       "   'usage': {'prompt_tokens': 22, 'completion_tokens': 24, 'total_tokens': 46},\n",
       "   'system_fingerprint': None}},\n",
       " 'error': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(\"batch_lsYz1K5XMMVUgGjsAA7oqvAy\").status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of 2021, the population of New York City is estimated to be around 8.4 million people.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(content.text)['response']['body']['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatAssistant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-65e2ce7f81eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0massistant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatAssistant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpt-3.5-turbo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'abc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massistant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# assistant.generate_batch_call(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#             rendered_prompt=\"Prompt\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#             system_instruction=\"Youre a good AI\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ChatAssistant' is not defined"
     ]
    }
   ],
   "source": [
    "assistant = ChatAssistant(model='gpt-3.5-turbo', api_key= 'abc')\n",
    "dir(assistant)\n",
    "# assistant.generate_batch_call(\n",
    "#             rendered_prompt=\"Prompt\",\n",
    "#             system_instruction=\"Youre a good AI\",\n",
    "#             external_messages=None,\n",
    "#             seed=None,\n",
    "#             desired_response_format='json',\n",
    "#             temperature=0.19,\n",
    "#             max_tokens = 2000,\n",
    "#             custom_id='request-1'\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gabriel.archangel import Archangel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity category': 'song', 'attribute category': 'sentiment'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gabriel.foundational_functions import *\n",
    "import json\n",
    "# from decorators import with_prompt\n",
    "json.loads(identify_categories(task_description= 'I am analyzing sentiment in songs', api_key = api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-af2e4b38c774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtwenty_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'talk.politics.misc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lfw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_lfw_pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lfw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_lfw_people\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_twenty_newsgroups\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_twenty_newsgroups\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_20newsgroups_vectorized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_openml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/_twenty_newsgroups.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_fetch_remote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRemoteFileMetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_dict_vectorizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_hash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureHasher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_to_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m def grid_to_graph(n_x, n_y, n_z=1, *, mask=None, return_as=sparse.coo_matrix,\n\u001b[0;32m--> 172\u001b[0;31m                   dtype=np.int):\n\u001b[0m\u001b[1;32m    173\u001b[0m     \"\"\"Graph of the pixel-to-pixel connections\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# Importing Tester requires importing all of UnitTest which is not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',shuffle=True, random_state=42, categories =['talk.politics.misc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "texts = pd.DataFrame(twenty_train.data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliottmokski/opt/anaconda3/lib/python3.8/site-packages/gabriel/archangel.py:57: UserWarning: Reset Files is set to True. Your files will be overwritten.\n",
      "  warnings.warn(\"Reset Files is set to True. Your files will be overwritten.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new file at /Users/elliottmokski/Downloads/sk_learn_politics2.csv\n",
      "Extracting categories for task: I am analyzing political lean in online news forums.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the parameters for this run:\n",
      "\n",
      "{\n",
      "    \"model\": \"gpt-3.5-turbo\",\n",
      "    \"n_parallel\": 50,\n",
      "    \"num_runs\": 10,\n",
      "    \"rate_first\": false,\n",
      "    \"temperature\": 0.8,\n",
      "    \"timeout\": 75,\n",
      "    \"truncate_len\": 5000,\n",
      "    \"seed\": null,\n",
      "    \"truncate\": true,\n",
      "    \"format\": \"json\",\n",
      "    \"batch_len\": 50\n",
      "}\n",
      "The output file will be saved at: /Users/elliottmokski/Downloads//sk_learn_politics2.csv\n",
      "Rough estimated cost in dollars: 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.71s/it]\n"
     ]
    }
   ],
   "source": [
    "task_description = \"I am analyzing political lean in online news forums.\"\n",
    "attribute_dict = {\n",
    "    'talks about politics': \"The 'talks about politics' attribute quantifies the extent to which the text is focused on political issues, debates, or events. It is high when politics is a central theme of the discussion, medium when politics is mentioned alongside other topics, and low or zero when politics is not mentioned at all.\",\n",
    "    'democratic leaning': \"The 'democratic leaning' attribute assesses the degree to which the text aligns with or supports values, policies, or figures associated with the Democratic Party. It is high when there is clear support or positive sentiment towards Democratic positions, low when there is minimal or indirect support, and zero when there is no alignment with Democratic views. You should infer this and rate if there in any implicit or explicit support for Democratic views. \",\n",
    "    'republican leaning': \"The 'republican leaning' attribute evaluates the extent to which the text aligns with or supports values, policies, or figures associated with the Republican Party. It is high when there is evident support or positive sentiment towards Republican positions, low when the support is minimal or indirect, and zero when there is no alignment with Republican views. You should infer this and rate if there in any implicit or explicit support for Republican views.\",\n",
    "    'exhibits anger': \"The 'exhibits anger' attribute measures the presence and intensity of anger in the text. It is high when the text displays strong feelings of anger or frustration, especially towards political figures, policies, or events; medium when anger is present but not the dominant emotion; and low or zero when there is no anger.\",\n",
    "    'exhibits rationality': \"The 'exhibits rationality' attribute determines the level of logical reasoning, evidence-based arguments, and objective analysis in the text. It is high when the text is characterized by clear, rational thought processes and a focus on facts; medium when rationality is present but mixed with subjective opinions; and low or zero when the text lacks rational argumentation or is primarily emotional.\"\n",
    "}\n",
    "archangel = Archangel(api_key = api_key)\n",
    "output_df = archangel.rate_texts(texts[:30], reset_files = True, task_description = task_description, attribute_dict= attribute_dict, save_folder = '/Users/elliottmokski/Downloads/', file_name = 'sk_learn_politics2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gabriel.archangel import Archangel\n",
    "# archangel = Archangel(api_key = '')\n",
    "# texts = ['This is a funny story' , \"This is a sad story\",\"John broke his leg\",'Archangel is a great tool','Archangel is a bad tool']\n",
    "# attribute_dict = {'happy':'happiness refers to joy and positivity','sad':'sad refers to sadness'}\n",
    "# task_description = 'I am rating sentiment in short stories'\n",
    "# archangel.rate_texts(texts, reset_files = True, task_description = task_description, attribute_dict= attribute_dict, save_folder = '/Users/elliottmokski/Downloads/', file_name = 'short_story_test_v9.csv', use_batch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('/Users/elliottmokski/Downloads/short_story_test_v4_batch_metadata.csv', index_col = 0)\n",
    "raw = pd.read_json('/Users/elliottmokski/Library/Application Support/GABRIEL Batch Calls/short_story_test_v4.jsonl', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The status of your batch is: completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internal logic for gpt eyes only</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The passage 'This is a funny story' presents a...</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>This is a funny story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Upon analyzing the passage provided, it is cru...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>This is a sad story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The passage 'John broke his leg' does not exhi...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>John broke his leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The passage 'Archangel is a great tool' convey...</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>Archangel is a great tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The passage 'Archangel is a bad tool' conveys ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Archangel is a bad tool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    internal logic for gpt eyes only happy  sad  \\\n",
       "0  The passage 'This is a funny story' presents a...    88   12   \n",
       "1  Upon analyzing the passage provided, it is cru...     0  100   \n",
       "2  The passage 'John broke his leg' does not exhi...     4    6   \n",
       "3  The passage 'Archangel is a great tool' convey...    85    5   \n",
       "4  The passage 'Archangel is a bad tool' conveys ...     0    0   \n",
       "\n",
       "                        Text  \n",
       "0      This is a funny story  \n",
       "1        This is a sad story  \n",
       "2         John broke his leg  \n",
       "3  Archangel is a great tool  \n",
       "4    Archangel is a bad tool  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gabriel.openai_api_calls import BatchRunner\n",
    "BatchRunner('').retrieve_batch('/Users/elliottmokski/Downloads/short_story_test_v9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internal logic for gpt eyes only</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The passage consists of the statement 'This is...</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>This is a funny story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The passage consists of a simple statement 'Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>This is a sad story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Upon careful analysis of the passage, it is ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>John broke his leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The passage 'Archangel is a great tool' carrie...</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>Archangel is a great tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The passage 'Archangel is a bad tool' conveys ...</td>\n",
       "      <td>12</td>\n",
       "      <td>75</td>\n",
       "      <td>Archangel is a bad tool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    internal logic for gpt eyes only  happy  sad  \\\n",
       "0  The passage consists of the statement 'This is...     80   20   \n",
       "1  The passage consists of a simple statement 'Th...      0  100   \n",
       "2  Upon careful analysis of the passage, it is ev...      0    0   \n",
       "3  The passage 'Archangel is a great tool' carrie...     18   12   \n",
       "4  The passage 'Archangel is a bad tool' conveys ...     12   75   \n",
       "\n",
       "                        Text  \n",
       "0      This is a funny story  \n",
       "1        This is a sad story  \n",
       "2         John broke his leg  \n",
       "3  Archangel is a great tool  \n",
       "4    Archangel is a bad tool  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('/Users/elliottmokski/Downloads/short_story_test_v5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_swVBC9X0NVcK5xuBaJj9rGmM', completion_window='24h', created_at=1718829780, endpoint='/v1/chat/completions', input_file_id='file-8oH3VvIL1IoEtt7N5MDZJdh8', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_type', line=1, message=\"Invalid type for 'custom_id': expected a string, but got an integer instead.\", param='custom_id'), BatchError(code='invalid_type', line=2, message=\"Invalid type for 'custom_id': expected a string, but got an integer instead.\", param='custom_id'), BatchError(code='invalid_type', line=3, message=\"Invalid type for 'custom_id': expected a string, but got an integer instead.\", param='custom_id'), BatchError(code='invalid_type', line=4, message=\"Invalid type for 'custom_id': expected a string, but got an integer instead.\", param='custom_id'), BatchError(code='invalid_type', line=5, message=\"Invalid type for 'custom_id': expected a string, but got an integer instead.\", param='custom_id')], object='list'), expired_at=None, expires_at=1718916180, failed_at=1718829781, finalizing_at=None, in_progress_at=None, metadata={'description': 'I am rating sentiment in short stories'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(test.loc['id','Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open /Users/elliottmokski/Library/Application Support/GABRIEL Batch Calls/short_story_test.jsonl\n",
    "import pandas as pd\n",
    "df = pd.read_json('/Users/elliottmokski/Library/Application Support/GABRIEL Batch Calls/short_story_test.jsonl', lines = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_dict = {'happy':'happiness refers to joy and positivity','sad':'sad refers to sadness'}\n",
    "\n",
    "params = {\n",
    "    'entity_category': '', 'attribute_category': '', 'api_key': api_key,\n",
    "    'model': 'gpt-3.5-turbo', 'temperature': 0.8,\n",
    "    'use_classification': False, 'format': 'json', 'project_probs': False, 'truncate': True,\n",
    "    'seed': None, 'timeout': 75, 'truncate_len': 9500, 'classification_clarification':'','text':'John broke his foot'\n",
    "}\n",
    "\n",
    "assistant = CombinedAssistant(api_key = api_key)\n",
    "output_df = assistant.rate_single_text(attribute_dict= attribute_dict, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "imdb = pd.read_csv('/Users/elliottmokski/Downloads/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliottmokski/opt/anaconda3/lib/python3.8/site-packages/GABRIEL/archangel.py:54: UserWarning: Reset Files is set to True. Your files will be overwritten.\n",
      "  warnings.warn(\"Reset Files is set to True. Your files will be overwritten.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new file at /Users/elliottmokski/Downloads/imdb_test.csv\n",
      "Extracting categories for task: I am rating sentiment in IMBD reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the parameters for this run:\n",
      "\n",
      "{\n",
      "    \"model\": \"gpt-3.5-turbo\",\n",
      "    \"n_parallel\": 50,\n",
      "    \"num_runs\": 10,\n",
      "    \"rate_first\": false,\n",
      "    \"temperature\": 0.8,\n",
      "    \"timeout\": 75,\n",
      "    \"truncate_len\": 5000,\n",
      "    \"seed\": null,\n",
      "    \"truncate\": true,\n",
      "    \"format\": \"json\",\n",
      "    \"batch_len\": 50\n",
      "}\n",
      "The output file will be saved at: /Users/elliottmokski/Downloads//imdb_test.csv\n",
      "Rough estimated cost in dollars: 0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:10<00:00,  5.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>positivity</th>\n",
       "      <th>negativity</th>\n",
       "      <th>discusses food</th>\n",
       "      <th>internal logic for gpt eyes only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Upon analyzing the movie review passage, it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The passage exudes a mix of nostalgic apprecia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The movie review passage conveys a generally p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The passage describes a family scenario with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The movie review passage paints a sophisticate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Daniel Day-Lewis is the most versatile actor a...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The movie review passage showcases a mix of se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>My guess would be this was originally going to...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The movie review passage critiques the film fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Well, I like to watch bad horror B-Movies, cau...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The movie review passage exhibits a predominan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>This IS the worst movie I have ever seen, as w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The movie review passage is filled with overwh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I have been a Mario fan for as long as I can r...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Upon analyzing the passage, it is evident that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  happy   sad  \\\n",
       "0   One of the other reviewers has mentioned that ...   12.0  62.0   \n",
       "1   A wonderful little production. <br /><br />The...   83.0  12.0   \n",
       "2   I thought this was a wonderful way to spend ti...   78.0  12.0   \n",
       "3   Basically there's a family where a little boy ...   10.0  58.0   \n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...   32.0  32.0   \n",
       "..                                                ...    ...   ...   \n",
       "95  Daniel Day-Lewis is the most versatile actor a...   85.0  12.0   \n",
       "96  My guess would be this was originally going to...   12.0   6.0   \n",
       "97  Well, I like to watch bad horror B-Movies, cau...    5.0  70.0   \n",
       "98  This IS the worst movie I have ever seen, as w...    5.0  90.0   \n",
       "99  I have been a Mario fan for as long as I can r...   73.0  12.0   \n",
       "\n",
       "    positivity  negativity  discusses food  \\\n",
       "0         35.0        78.0             0.0   \n",
       "1         92.0        14.0             0.0   \n",
       "2         86.0        14.0             5.0   \n",
       "3         32.0        60.0             0.0   \n",
       "4         48.0        52.0             0.0   \n",
       "..         ...         ...             ...   \n",
       "95        92.0        18.0             0.0   \n",
       "96         9.0        87.0             0.0   \n",
       "97        10.0        90.0             0.0   \n",
       "98         3.0        95.0             0.0   \n",
       "99        86.0        21.0            14.0   \n",
       "\n",
       "                     internal logic for gpt eyes only  \n",
       "0   Upon analyzing the movie review passage, it is...  \n",
       "1   The passage exudes a mix of nostalgic apprecia...  \n",
       "2   The movie review passage conveys a generally p...  \n",
       "3   The passage describes a family scenario with a...  \n",
       "4   The movie review passage paints a sophisticate...  \n",
       "..                                                ...  \n",
       "95  The movie review passage showcases a mix of se...  \n",
       "96  The movie review passage critiques the film fo...  \n",
       "97  The movie review passage exhibits a predominan...  \n",
       "98  The movie review passage is filled with overwh...  \n",
       "99  Upon analyzing the passage, it is evident that...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_dict = {\"happy\": \"\"\"The 'happy' attribute refers to the extent to which the text has a positive or happy attitude. It is high if the text manifest a clearly jovial or positive sentiment.\"\"\",\n",
    "                  \"sad\":\"The 'sad' attribute refers to whether the text has an overall sad or glum sentiment. It is high if the text showcases a largely sad or depressing sentiment.\",\n",
    "                  \"positivity\":\"The 'positivity' attribute refers to the extent to which the text has a positive or supportive attitude towards the film, indicating that the reviewer has a high opinion of the film\",\n",
    "                \"negativity\":\"The 'negativity' attribute refers to the extent to which the text has a negative attitude towards the film, indicating that the reviewer did not enjoy the film or has a low opinion of it\",\n",
    "                  \"discusses food\": \"The 'discusses food' attribute is high when the text in question mentions food a lot or otherwise focuses on food. It is low if food mentions are rare, and 0 if there is no mention or allusion to food at all.\"}\n",
    "archangel = Archangel(api_key = api_key)\n",
    "texts = imdb['review'][:100]\n",
    "task_description = 'I am rating sentiment in IMBD reviews'\n",
    "archangel.rate_texts(texts, reset_files = True, task_description = task_description, attribute_dict= attribute_dict, save_folder = '/Users/elliottmokski/Downloads/', file_name = 'imdb_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
